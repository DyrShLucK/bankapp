apiVersion: v1
kind: ConfigMap
resources:
  requests:
    cpu: "100m"
    memory: "512Mi"
  limits:
    cpu: "1000m"
    memory: "2Gi"

volumeClaimTemplate:
  accessModes: ["ReadWriteOnce"]
  resources:
    requests:
      storage: 512Mi
metadata:
  name: logstash-pipeline
  namespace: logging
logstashPipeline:
  logstash.conf: |
    input {
      kafka {
        bootstrap_servers => "kafka.kafka-dev.svc.cluster.local:9092" # Адрес Kafka-сервера в кластере
        topics => ["bank-app-logs"] # Название топика
        group_id => "logstash-consumer-group" # Consumer Group ID
        codec => json # Предполагается, что логи в JSON
        auto_offset_reset => "latest" # Начинать с последнего сообщения
      }
    }

    filter {
      if [message] {
        json {
          source => "message"
        }
      }
      # Пример маскировки чувствительных данных (не идеальное решение, лучше на уровне микросервиса)
      # mutate {
      #   gsub => [
      #     "[some_field]", "(\d{4})\d{4}(\d{4})", "\1****\2"
      #   ]
      # }
    }

    output {
      elasticsearch {
        hosts => ["http://elasticsearch-master.log.svc.cluster.local:9200"] 
        index => "bank-logs-%{+YYYY.MM.dd}" 
        manage_template => false 
      }
    }