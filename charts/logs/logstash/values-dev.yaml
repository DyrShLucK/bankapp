apiVersion: v1
kind: ConfigMap
resources:
  requests:
    cpu: "50m"
    memory: "128Mi"
  limits:
    cpu: "100m"
    memory: "256Mi"

volumeClaimTemplate:
  accessModes: ["ReadWriteOnce"]
  resources:
    requests:
      storage: 256Mi
metadata:
  name: logstash-pipeline
  namespace: logging
logstashPipeline:
  logstash.conf: |
    input {
      kafka {
        bootstrap_servers => "kafka.prod.svc.cluster.local:9092" # Адрес Kafka-сервера в кластере
        topics => ["bank-app-logs"] # Название топика
        group_id => "logstash-consumer-group" # Consumer Group ID
        codec => json # Предполагается, что логи в JSON
        auto_offset_reset => "latest" # Начинать с последнего сообщения
      }
    }

    filter {
      # Пример фильтрации и парсинга JSON
      if [message] {
        json {
          source => "message"
        }
      }
      # Пример маскировки чувствительных данных (не идеальное решение, лучше на уровне микросервиса)
      # mutate {
      #   gsub => [
      #     "[some_field]", "(\d{4})\d{4}(\d{4})", "\1****\2"
      #   ]
      # }
    }

    output {
      elasticsearch {
        hosts => ["http://elasticsearch-es-http.logging.svc.cluster.local:9200"] # Адрес ES в кластере
        index => "bank-logs-%{+YYYY.MM.dd}" # Индекс с временным шаблоном
        manage_template => false # Управление шаблонами через Kibana или отдельный Job
      }
    }